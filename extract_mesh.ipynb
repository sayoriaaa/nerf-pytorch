{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import run_nerf\n",
    "import run_nerf_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = './logs'\n",
    "run = 'ship'\n",
    "\n",
    "if run == 'ship':\n",
    "    expname = 'blender_paper_ship'\n",
    "    ckpt = '050000.tar'\n",
    "    dataset = 'ship' # used when config file of pretrained model not provided\n",
    "\n",
    "elif run == 'lego':\n",
    "    expname = 'lego_test'\n",
    "    ckpt = '200000.tar'\n",
    "    dataset = 'lego'\n",
    "\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "try:\n",
    "    config = os.path.join(basedir, expname, 'config.txt')\n",
    "    print('Args:')\n",
    "    print(open(config, 'r').read())\n",
    "except Exception as e: # config file not provided\n",
    "    config = os.path.join('./configs', dataset+'.txt')\n",
    "    print('Args:')\n",
    "    print(open(config, 'r').read())\n",
    "\n",
    "\n",
    "parser = run_nerf.config_parser()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "ft_str = '' \n",
    "ft_str = '--ft_path {}'.format(os.path.join(basedir, expname, ckpt))\n",
    "args = parser.parse_args('--config {} --ft_path {} --device {}'.format(\n",
    "                                                            config, \n",
    "                                                            os.path.join(basedir, expname, ckpt),\n",
    "                                                            device\n",
    "                                                            ))\n",
    "# pprint.pprint(args)\n",
    "# Create nerf model\n",
    "_, render_kwargs_test, start, grad_vars, models = run_nerf.create_nerf(args)\n",
    "\n",
    "net_fn = render_kwargs_test['network_query_fn']\n",
    "\n",
    "# Render an overhead view to check model was loaded correctly\n",
    "c2w = torch.eye(4, dtype=torch.float32)# identity pose matrix\n",
    "c2w[2,-1] = 4.\n",
    "# c2w = c2w.to(device)\n",
    "\n",
    "near = 2.\n",
    "far = 6.\n",
    "bds_dict = {\n",
    "        'near' : near,\n",
    "        'far' : far,\n",
    "    }\n",
    "render_kwargs_test.update(bds_dict)\n",
    "\n",
    "H, W, focal = 800, 800, 1200.\n",
    "down = 8\n",
    "H, W, focal = H//down, W//down, focal/down\n",
    "\n",
    "K = np.array([\n",
    "    [focal, 0, 0.5*W],\n",
    "    [0, focal, 0.5*H],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    rgb, disp, acc, _ = run_nerf.render(H, W, K, chunk=args.chunk, c2w=c2w[:3,:4], **render_kwargs_test)\n",
    "test = rgb.cpu().numpy()\n",
    "img = np.clip(test,0,1)\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query network on dense 3d grid of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "bound = 1.2\n",
    "t = np.linspace(-1*bound, bound, N+1)\n",
    "\n",
    "query_pts = np.stack(np.meshgrid(t, t, t), -1).astype(np.float32)\n",
    "print(query_pts.shape)\n",
    "sh = query_pts.shape\n",
    "flat = query_pts.reshape([-1,3])\n",
    "flat = torch.tensor(flat)\n",
    "    \n",
    "fn = lambda i0, i1 : net_fn(flat[i0:i1,None,:], viewdirs=torch.zeros_like(flat[i0:i1]), network_fn=render_kwargs_test['network_fine'])\n",
    "chunk = 1024*64\n",
    "with torch.no_grad():\n",
    "    raw = torch.concatenate([fn(i, i+chunk) for i in range(0, flat.shape[0], chunk)], 0)\n",
    "raw = torch.reshape(raw, list(sh[:-1]) + [-1])\n",
    "raw = raw.cpu().numpy()\n",
    "sigma = np.maximum(raw[...,-1], 0.)\n",
    "\n",
    "print(raw.shape)\n",
    "plt.hist(np.maximum(0,sigma.ravel()), log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marching cubes with [PyMCubes](https://github.com/pmneila/PyMCubes)\n",
    "Change `threshold` to use a different sigma threshold for the isosurface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mcubes\n",
    "\n",
    "threshold = 50.\n",
    "print('fraction occupied', np.mean(sigma > threshold))\n",
    "vertices, triangles = mcubes.marching_cubes(sigma, threshold)\n",
    "print('done', vertices.shape, triangles.shape)\n",
    "vertices = 2*bound*vertices/N-bound # project back to nerf coordination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read vertex color through NeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# i found x,y is inversed in texture, but haven't know why, so i did this for quick solve\n",
    "vertices = vertices[...,[1,0,2]]\n",
    "flat = torch.tensor(vertices, dtype=torch.float32)\n",
    "fn = lambda i0, i1 : net_fn(flat[i0:i1,None,:], viewdirs=torch.zeros_like(flat[i0:i1]), network_fn=render_kwargs_test['network_fine'])\n",
    "with torch.no_grad():\n",
    "    raw = torch.concatenate([fn(i, i+chunk) for i in range(0, flat.shape[0], chunk)], 0)\n",
    "raw = torch.reshape(raw, [flat.shape[0], -1])\n",
    "raw = raw.cpu().numpy()\n",
    "print(raw.shape)\n",
    "rgb = 1./(1 + np.exp(-1*raw[...,:3]))\n",
    "print(rgb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live preview with [trimesh](https://github.com/mikedh/trimesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "plot_texture = True\n",
    "\n",
    "if plot_texture:\n",
    "    mesh = trimesh.Trimesh(vertices, triangles, vertex_colors=rgb)\n",
    "else:\n",
    "    mesh = trimesh.Trimesh(vertices, triangles)\n",
    "\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = mesh.export(dataset+'.obj', \n",
    "            header='https://github.com/sayoriaaa/nerf-pytorch',\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ship'\n",
    "mesh = trimesh.load(dataset+'.obj')\n",
    "mesh.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
